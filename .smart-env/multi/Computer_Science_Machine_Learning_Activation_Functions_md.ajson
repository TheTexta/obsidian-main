
"smart_sources:Computer Science/Machine Learning/Activation Functions.md": {"path":"Computer Science/Machine Learning/Activation Functions.md","last_embed":{"hash":null},"embeddings":{},"last_read":{"hash":"1tz5zkg","at":1756337133342},"class_name":"SmartSource","last_import":{"mtime":1756335618061,"size":1571,"at":1756337133355,"hash":"1tz5zkg"},"blocks":{"#":[1,2],"##But what exactly is an activation function?":[3,5],"##But what exactly is an activation function?#{1}":[4,5],"##How do they work?":[6,13],"##How do they work?#{1}":[7,13]},"outlinks":[{"title":"linear functions","target":"Linear Equation","line":1},{"title":"ReLU Activation","target":"ReLU Activation","line":1},{"title":"Machine Learning","target":"Machine Learning","line":7},{"title":"sigmoid function","target":"sigmoid function","line":7},{"title":"ReLU Activation","target":"ReLU Activation","line":8},{"title":"Linear Activation","target":"Linear Activation","line":9},{"title":"Sigmoid Activation","target":"Sigmoid Activation","line":10},{"title":"Softmax Activation","target":"Softmax Activation","line":11}],"task_lines":[]},
"smart_sources:Computer Science/Machine Learning/Activation Functions.md": {"path":"Computer Science/Machine Learning/Activation Functions.md","embeddings":{"TaylorAI/bge-micro-v2":{"vec":[-0.01109134,-0.05410497,0.00815751,-0.05849886,-0.04977226,0.07360461,0.05486305,0.06720738,0.05168518,-0.02832972,0.00894699,-0.02662171,0.05223575,0.03050076,0.00527565,0.03624494,0.00503299,0.05670107,-0.0730937,-0.0753421,0.07894961,-0.03318572,-0.02821186,-0.05110561,0.04088462,-0.04429176,-0.0143463,0.03717288,-0.07519272,-0.20592578,-0.00038489,-0.01984248,0.11719032,-0.04312304,-0.03709191,-0.0277705,-0.01522193,0.00003594,-0.04365751,0.02162285,0.07636874,-0.04473964,0.02279861,-0.02544297,0.01612935,-0.02845283,-0.02224317,-0.04081369,0.00023728,0.03097744,0.01635709,0.00691375,-0.00001219,0.02454004,0.06265295,0.01162095,0.05729727,0.07003472,0.05061085,0.02595773,0.03248646,0.07083929,-0.1774869,0.04620214,0.00770491,-0.04916387,-0.01428671,-0.13539726,0.00132139,0.0715577,-0.05132141,0.01068939,0.02255816,0.01203961,0.00524806,0.04369579,-0.0006692,-0.0236175,-0.01632672,-0.00246836,0.03812812,-0.00606785,-0.04652658,0.01603212,0.01743976,0.01958755,-0.02862589,-0.02079697,-0.01169043,0.00480993,0.03243358,0.03952463,-0.00936947,-0.0013447,-0.05924912,0.00270697,0.03597894,0.03837591,-0.10280756,0.10853715,-0.05938151,0.02158344,-0.00676339,0.00757332,0.03701927,-0.03370022,-0.05415364,0.01388336,-0.04512049,-0.03623677,-0.05053967,-0.07983926,0.00673568,-0.01025427,-0.01054918,0.08731452,0.02941919,0.00346822,0.00425141,-0.05428276,0.01897032,0.01802026,0.01956416,0.02910403,0.04195682,-0.00625733,0.02699801,0.08978093,0.02545835,0.06038433,0.02150809,-0.00847748,-0.02050083,0.06046797,0.02857593,0.00841815,0.01111103,-0.04763803,-0.05399395,0.0230477,-0.0086447,0.07216378,0.05874297,-0.05331601,-0.0446234,0.11398878,-0.04088713,-0.00114919,0.00981691,-0.02178835,0.00592012,0.08081008,-0.06045826,-0.02549268,0.01632767,0.04793585,-0.0116675,-0.05199288,-0.09593495,-0.01456135,-0.11001367,-0.02549556,-0.06554226,0.13948703,0.05496875,0.0005027,-0.0240256,-0.02321786,0.00080191,-0.00954925,0.01538521,0.02528146,-0.03088041,-0.04429162,0.03150667,0.00475408,-0.05216602,-0.03323406,-0.01961068,0.01757368,0.0217203,-0.0888831,-0.01935432,-0.00763649,-0.01943097,-0.01814786,0.00690956,-0.07653571,-0.00289307,0.01926245,-0.07160363,0.03661394,-0.02218682,-0.02456825,-0.04863778,-0.08098058,-0.03439415,-0.04071157,-0.00808227,-0.00186236,-0.02199337,-0.05412185,0.05205055,-0.04397061,0.00506268,0.00877356,-0.01812578,0.00605692,0.06841865,0.00753977,0.01235245,-0.00421283,0.05027723,-0.05951681,-0.04375943,-0.06472561,0.01806656,0.02377492,-0.02196668,-0.0190246,0.06140544,0.01381353,-0.05978228,-0.18452267,-0.06142525,0.02263733,-0.02006188,0.06107373,-0.09007499,0.05806788,-0.01501262,-0.05950655,0.02421553,0.08006143,0.05270652,-0.05940139,-0.04095429,0.01455698,0.06163906,0.02213512,-0.05399133,-0.00859887,-0.03998597,-0.00307487,0.06404391,0.06412244,-0.0254729,0.05139447,0.03306053,0.12977935,-0.01917928,0.12971354,0.03442938,0.02747293,-0.04244876,-0.01331074,0.00755568,0.04962664,0.00440449,0.08804939,-0.01182284,-0.05058366,-0.03271318,-0.02993672,0.00347542,-0.02157059,-0.03918904,-0.0212307,0.08295789,-0.04778565,0.02177792,-0.05939524,0.02038923,-0.00243622,-0.02156699,0.04994744,0.07744657,0.01935066,-0.01643145,-0.03528969,-0.01924248,-0.05486468,0.04682156,-0.01094529,-0.0722902,-0.07323045,-0.09647031,0.06363423,-0.00434606,0.00011893,-0.01038521,0.09491692,0.00972227,-0.01201994,0.11661832,0.02161866,0.0194026,0.04640269,0.00395053,0.0432715,-0.01462265,-0.02046368,0.00303125,0.05168031,-0.02337827,0.00761831,-0.01730867,0.0421641,-0.03393272,0.08718476,-0.0566242,0.01464305,0.02163373,-0.05402853,-0.00445979,0.01001783,0.00580143,0.06604695,0.01208108,-0.24209501,-0.0129691,0.017927,0.05197166,-0.04298702,-0.05237073,0.07918778,-0.02913076,-0.06065298,0.0069997,0.05609437,0.03792128,0.03519979,-0.00674981,-0.03849166,0.00167609,0.0295425,-0.00203069,0.02992652,-0.05402335,0.02375147,0.06101841,0.1906745,-0.08243399,0.04468501,0.03141788,-0.01951296,-0.03370116,0.06670327,-0.03099266,0.09815501,0.01086903,0.0539943,-0.03085894,-0.03638997,0.08181657,-0.0224302,0.02752483,0.04314238,-0.00882674,0.01093854,0.02014031,-0.07234066,-0.00609274,0.09056115,-0.0303244,0.04279875,-0.08052401,0.0101287,0.04702368,0.02142346,0.04934158,0.02274628,-0.02833451,0.04916634,0.03461763,-0.01209111,-0.02717488,-0.08433997,0.05188795,0.02594386,-0.05039778,0.06433423,0.07803288,-0.08605944],"last_embed":{"hash":"1tz5zkg","tokens":349}}},"last_read":{"hash":"1tz5zkg","at":1756337149883},"class_name":"SmartSource","last_import":{"mtime":1756335618061,"size":1571,"at":1756337133355,"hash":"1tz5zkg"},"blocks":{"#":[1,2],"##But what exactly is an activation function?":[3,5],"##But what exactly is an activation function?#{1}":[4,5],"##How do they work?":[6,13],"##How do they work?#{1}":[7,13]},"outlinks":[{"title":"linear functions","target":"Linear Equation","line":1},{"title":"ReLU Activation","target":"ReLU Activation","line":1},{"title":"Machine Learning","target":"Machine Learning","line":7},{"title":"sigmoid function","target":"sigmoid function","line":7},{"title":"ReLU Activation","target":"ReLU Activation","line":8},{"title":"Linear Activation","target":"Linear Activation","line":9},{"title":"Sigmoid Activation","target":"Sigmoid Activation","line":10},{"title":"Softmax Activation","target":"Softmax Activation","line":11}],"task_lines":[],"last_embed":{"hash":"1tz5zkg","at":1756337149855}},"smart_blocks:Computer Science/Machine Learning/Activation Functions.md#": {"path":null,"embeddings":{"TaylorAI/bge-micro-v2":{"vec":[-0.01710908,-0.04459883,0.01867045,-0.05699463,-0.03743224,0.0579905,0.06163934,0.06950831,0.04720249,-0.03948219,-0.00653125,-0.03086175,0.04816146,0.04502869,0.00174213,0.03108855,0.00434002,0.06826742,-0.07155103,-0.07164782,0.08248743,-0.02455174,-0.02237299,-0.05651366,0.02513413,-0.04344843,-0.00878061,0.03293363,-0.0699792,-0.19448158,-0.00448243,-0.01098706,0.10720238,-0.04267682,-0.03986325,-0.02369713,-0.0406802,0.0128015,-0.04649834,0.02571609,0.05823686,-0.04814879,0.02341906,-0.03614058,0.00816836,-0.01560751,-0.02198945,-0.03082136,0.00961204,0.01158517,0.02078623,0.0229751,-0.00175559,0.0290925,0.05467792,0.00201625,0.05420868,0.06885189,0.05070578,0.02033335,0.04466898,0.06513632,-0.1705271,0.03348286,-0.00377924,-0.05640981,-0.00339924,-0.13132861,-0.00555613,0.06776253,-0.05639359,0.00594487,0.00696771,0.01491302,0.00854855,0.04184538,0.00378159,-0.03657429,-0.0131776,0.00415947,0.05612834,0.00161172,-0.04039084,0.01326363,0.02676005,0.01298719,-0.02990159,-0.01459291,-0.01132711,-0.00259693,0.04123764,0.04558368,-0.00759288,-0.01087136,-0.06163438,-0.00098876,0.02576845,0.03173601,-0.09175381,0.12540416,-0.06589694,0.02467895,0.0033085,0.02037057,0.03357782,-0.02874113,-0.05133776,0.02729187,-0.04086225,-0.03322728,-0.04607534,-0.085707,0.01778007,-0.00750685,-0.01232719,0.08970822,0.03743145,-0.00181876,0.00803374,-0.05680149,0.01330389,0.01025386,0.01817179,0.02702799,0.04394674,-0.01610153,0.02564777,0.08411689,0.02369034,0.05872105,0.0305899,-0.00829279,-0.01433294,0.04592335,0.03462635,0.00897642,0.01548855,-0.06338894,-0.06155926,0.01765881,-0.02483611,0.05902037,0.06653375,-0.05908754,-0.02858765,0.10296829,-0.04624519,0.01238954,-0.00723634,-0.01834447,0.00228146,0.08312254,-0.04696624,-0.02511416,0.03158029,0.03946382,-0.0172422,-0.05939176,-0.0927312,-0.01850132,-0.10037255,-0.03108358,-0.07498597,0.15953818,0.04409937,0.00363824,-0.02813604,-0.03467478,0.00797187,-0.01181431,0.02013252,0.02953682,-0.03237802,-0.03732354,0.03512214,0.0086968,-0.06023049,-0.03463772,-0.03599521,0.01906368,0.02827151,-0.0905147,-0.02481189,-0.00453644,-0.0252969,-0.02138527,0.00294523,-0.06649136,-0.00869354,0.0252283,-0.06833968,0.03877614,-0.01605142,-0.02865621,-0.04324769,-0.08417681,-0.03541623,-0.04327333,-0.0046253,-0.01240468,-0.0380929,-0.05481689,0.03766779,-0.03259002,0.01257666,0.01091951,-0.01180487,0.00048005,0.06311167,0.01199406,-0.00420766,-0.00859835,0.05418883,-0.07606865,-0.04710522,-0.05412812,0.01239169,0.01324101,-0.01291911,-0.02148303,0.08136183,0.01479601,-0.05339028,-0.18246089,-0.06979387,0.01300743,-0.03646184,0.08052761,-0.0771913,0.06294352,-0.01168234,-0.05749152,0.02050706,0.06592695,0.05181233,-0.04686021,-0.0285196,0.01632148,0.06245586,0.02747875,-0.05656257,-0.01296517,-0.03922103,-0.00430367,0.06798741,0.06014643,-0.01566885,0.05585431,0.03512534,0.1252847,-0.02585426,0.1296556,0.02529898,0.02710018,-0.03528213,-0.00420357,0.0191587,0.06764189,0.00856842,0.0767562,-0.0200742,-0.04425175,-0.03436681,-0.01859686,0.01853327,-0.0177185,-0.03552357,-0.02674865,0.06579636,-0.0464009,0.01787289,-0.06955712,0.02255175,-0.00273918,-0.02632394,0.03968458,0.0717923,0.02048651,0.00384668,-0.03411545,-0.02540368,-0.06042439,0.04761373,-0.00975482,-0.06862662,-0.0852726,-0.10209393,0.0561232,0.01075578,-0.00441243,-0.00980791,0.10235782,0.02627288,-0.00827214,0.127676,0.01200459,0.02028741,0.03519369,-0.00592534,0.04421601,-0.0240915,-0.01618942,0.01692264,0.06891234,-0.01327502,0.02078099,-0.01628491,0.04961847,-0.03752702,0.08311208,-0.03814358,0.01761578,0.00431259,-0.04705586,-0.01741933,0.01099815,0.00794785,0.06834279,0.0054611,-0.23427886,-0.00748637,0.01530037,0.05487501,-0.04776816,-0.03405264,0.06636789,-0.02685598,-0.05545892,0.01406161,0.0606397,0.03818459,0.03496845,-0.00738575,-0.04202571,0.00023614,0.03418778,-0.01989455,0.03653049,-0.06238136,0.02367984,0.06063573,0.19798177,-0.07726882,0.04785904,0.01727363,-0.02006563,-0.03366686,0.04199407,-0.03120306,0.11535913,0.01301067,0.0411307,-0.03493024,-0.03633769,0.10235373,-0.01154036,0.02396823,0.04758059,-0.01818657,-0.00808775,0.01384414,-0.08343434,-0.00339132,0.09760312,-0.03602727,0.03632211,-0.07496535,0.00605784,0.04753778,0.02012067,0.04672641,0.01525765,-0.03570268,0.04684884,0.0415795,-0.01289721,-0.03428429,-0.08160481,0.04681005,0.04019001,-0.04473458,0.06863517,0.0781994,-0.09361835],"last_embed":{"hash":"62datv","tokens":162}}},"text":null,"length":0,"last_read":{"hash":"62datv","at":1756337149864},"key":"Computer Science/Machine Learning/Activation Functions.md#","lines":[1,2],"size":795,"outlinks":[{"title":"linear functions","target":"Linear Equation","line":1},{"title":"ReLU Activation","target":"ReLU Activation","line":1}],"class_name":"SmartBlock","last_embed":{"hash":"62datv","at":1756337149864}},
"smart_blocks:Computer Science/Machine Learning/Activation Functions.md##But what exactly is an activation function?#{1}": {"path":null,"embeddings":{"TaylorAI/bge-micro-v2":{"vec":[-0.02034409,-0.04187525,0.00431654,-0.02706154,-0.06874792,0.08937031,0.08692268,0.09128696,0.06354434,-0.00247007,0.03406414,-0.02767774,0.04898417,-0.02074586,-0.00004084,0.01987093,-0.02189028,0.02656687,-0.06717988,-0.04628773,0.07903935,-0.03574135,-0.03170637,-0.04172036,0.05148184,0.0129809,-0.03557509,0.01000237,-0.06090779,-0.19749102,-0.01053936,-0.05084079,0.15653409,-0.04750289,0.00272775,-0.05719634,0.0425115,-0.00511834,-0.03801784,-0.00458445,0.05517726,-0.0186163,0.00735943,-0.01659816,0.02132955,-0.06456264,-0.02881777,-0.04170161,-0.03045699,0.05467391,0.01800936,-0.01086915,0.02142113,0.0218806,0.06351796,0.03519028,0.02024211,0.08426548,0.04471709,0.03406196,0.02170805,0.05386221,-0.15293141,0.05362418,0.06313155,-0.00846039,-0.01567488,-0.14719146,-0.01577716,0.0736293,-0.03691811,0.0218661,0.03621049,0.02826267,0.00267116,0.01446589,-0.02282678,0.00879242,-0.02032667,0.00942835,-0.00027833,-0.04934572,-0.06056639,0.04219408,-0.03708319,0.02441839,-0.0036281,-0.0599929,-0.00828423,0.01350854,0.01642043,-0.00447528,-0.00893831,0.03563168,-0.03065984,0.00804203,0.04695297,0.02757091,-0.07779283,0.13709807,-0.06244081,0.04147954,-0.0528628,-0.00795042,0.05228721,-0.01403492,-0.03667165,-0.01086709,-0.0466649,-0.05535056,-0.02593219,-0.05106583,-0.00985231,-0.0266664,0.01991664,0.07284701,0.02685052,0.02496427,0.02850105,-0.02658271,0.05041162,0.02418747,0.04538867,0.01341916,0.04140179,0.00263211,0.05502424,0.09145667,0.00204418,0.00927873,0.03328295,-0.02710653,-0.07190506,0.04326977,0.03331931,0.03960082,0.01222835,-0.00404033,-0.04253117,0.01727619,0.01934556,0.08631565,0.04260684,-0.0640072,-0.03328471,0.10853862,0.00519748,-0.00515373,0.0392618,-0.01016689,-0.0369591,0.03139104,-0.08809867,-0.03421347,-0.06176782,0.07053233,-0.02407085,-0.05152267,-0.06998436,-0.00752549,-0.09999292,-0.00767562,-0.04138079,0.11279082,0.02853253,-0.00105667,-0.0225043,0.00987929,-0.00389408,-0.02242653,0.00904401,0.02218886,-0.07144172,-0.05747435,0.04198432,-0.01507095,-0.03581849,-0.02647713,0.02007245,-0.02830252,0.06736932,-0.06500827,-0.00369871,-0.00098478,0.01171465,-0.01201711,-0.02947875,-0.06545811,0.03761359,-0.02622351,-0.05611403,0.04325143,-0.04100381,-0.02442521,-0.04422922,-0.08481617,-0.02993663,-0.02220699,-0.00735526,0.01679821,0.02225681,-0.03936072,0.05214604,-0.01895588,-0.04979115,0.00401583,0.00168638,0.01464518,0.08678069,-0.01436002,-0.00286184,0.01872128,0.0263615,-0.01147653,-0.04495394,-0.06230117,0.01612423,0.01346162,-0.03208262,-0.02223166,0.00861025,-0.00020685,-0.02899674,-0.18702883,-0.05114762,0.02908001,0.013981,0.04658094,-0.05931441,0.03566926,-0.00845295,-0.06236812,0.01292174,0.09485458,0.07575344,-0.06832062,-0.02532645,0.00583143,0.04543628,-0.02135541,-0.0797459,0.01112378,-0.02329998,-0.02468318,0.05417147,0.01423107,-0.05788012,0.0399789,0.02512536,0.13196886,0.024843,0.12285805,0.05250045,0.04285304,-0.05224706,-0.05153377,-0.01313168,0.02085269,0.00908979,0.06997894,-0.02509067,-0.0569407,-0.02951934,-0.05854895,-0.02996527,-0.03003181,-0.06366985,0.0335671,0.11403903,-0.05423925,0.03183084,-0.01460964,0.04297964,0.0243888,-0.02309949,0.05788799,0.08407185,-0.00213709,-0.04718319,-0.02469003,-0.01036053,-0.03162449,0.03963683,-0.00457751,-0.04019041,-0.05704892,-0.05266731,0.05242959,0.00106971,-0.01101055,-0.05238672,0.06308317,-0.03820015,-0.00659219,0.124818,0.01023876,-0.03165786,0.04483319,0.02097647,0.03414026,0.00464817,-0.0077887,-0.02758034,0.02624857,-0.04662383,-0.02365359,0.01242241,0.00524923,-0.03900069,0.05999415,-0.06242448,0.00042615,0.00972264,-0.08183379,0.04591377,-0.02445294,-0.01979611,0.00022504,0.00225317,-0.25462958,-0.01562471,0.02064644,0.03573788,-0.04343953,-0.05153908,0.09963452,-0.01259036,-0.11396207,0.04168138,0.05422042,0.02017895,-0.00477452,0.00349146,-0.04361537,0.01050398,0.06574091,-0.01730739,0.01885302,-0.04050944,0.01735328,0.07498875,0.20817521,-0.06010047,0.05189979,0.03171119,-0.00345775,-0.01059259,0.10661944,-0.02100409,0.05820834,-0.0051001,0.06580666,-0.04646735,-0.01980895,0.02550918,0.02210052,0.06957126,0.0108869,-0.00853213,0.00685466,-0.00602936,-0.05549374,-0.01639605,0.05926269,-0.011027,0.03614433,-0.07228126,-0.00042984,0.04041767,0.02847661,0.0564296,0.05076859,-0.0381613,0.05444987,0.01908874,-0.01071748,-0.0211568,-0.05273584,0.06745325,-0.00280308,-0.03460399,0.08958323,0.07691438,-0.03480373],"last_embed":{"hash":"bs3ed6","tokens":83}}},"text":null,"length":0,"last_read":{"hash":"bs3ed6","at":1756337149873},"key":"Computer Science/Machine Learning/Activation Functions.md##But what exactly is an activation function?#{1}","lines":[4,5],"size":291,"outlinks":[],"class_name":"SmartBlock","last_embed":{"hash":"bs3ed6","at":1756337149873}},
"smart_blocks:Computer Science/Machine Learning/Activation Functions.md##How do they work?#{1}": {"path":null,"embeddings":{"TaylorAI/bge-micro-v2":{"vec":[-0.01859571,-0.07926672,-0.00231761,-0.06695724,-0.05541823,0.04412339,0.04988793,0.06368491,0.01823318,-0.00606541,0.07876434,-0.00933653,0.03583573,0.01539905,0.02981545,0.04024122,0.00643703,0.06108513,-0.1003986,-0.07230806,0.06092228,-0.05716351,-0.04162955,-0.05339053,0.03881196,-0.01365696,-0.00566146,-0.00797468,-0.07379311,-0.19374928,0.01453402,-0.0053646,0.13816313,-0.01972543,-0.05170609,-0.02887615,0.01707217,0.01434336,-0.05102156,0.03695487,0.07386311,-0.07004577,-0.01012753,0.00654034,0.02175986,-0.04115527,-0.04258026,-0.0422693,-0.02381684,0.06387305,0.01275001,0.01843447,-0.00382432,0.01335933,0.06355977,0.01650654,0.07001939,0.04664057,0.04685983,0.02311653,0.03137619,0.07117087,-0.18831795,0.06690839,-0.02487397,-0.00305473,-0.02585449,-0.16636048,0.00705706,0.09801327,-0.04249535,-0.01513525,0.01106863,0.02709672,0.01017568,0.01725516,0.0022085,-0.01219167,-0.00255454,-0.03518727,-0.01935489,-0.04502128,-0.03197186,-0.00197048,0.00859839,0.02083621,-0.03870131,-0.01667679,0.02835767,0.00399582,0.02160151,0.02899766,0.01194255,-0.01643551,-0.06914927,0.00806666,0.06018726,0.04739128,-0.08764419,0.11277086,-0.05939668,0.01873643,-0.03194268,-0.00904838,0.01824338,-0.03222738,-0.06364119,-0.02276188,-0.02495815,-0.02120525,-0.07282975,-0.06237402,-0.01012886,0.0176158,-0.006904,0.02270005,0.03351671,0.00742601,0.02024418,-0.06192496,0.02131918,0.02362644,0.0213195,0.0063798,0.01434749,-0.01426304,0.01004672,0.07542784,0.02815103,0.03103538,0.02550679,0.00310095,-0.04451108,0.06686628,0.00816555,0.01463056,0.04932068,-0.03927959,-0.01309101,0.05154961,0.00661599,0.09039684,0.05647863,-0.05349867,-0.02136468,0.11009653,-0.06140373,0.01226631,0.00768587,0.00346269,0.03632737,0.07652304,-0.05648061,-0.02396158,0.00825248,0.03207184,0.00747613,-0.03590956,-0.06860227,0.00497581,-0.10422519,-0.02168404,-0.07550196,0.14723079,0.05743882,-0.00154931,-0.01805094,0.01391496,-0.01948031,-0.00408952,0.01520814,0.02668617,-0.01444235,-0.03344568,0.05348912,0.02288855,-0.03981638,-0.01548436,-0.01087565,0.04010769,0.01671812,-0.09531103,-0.02028367,-0.00301278,-0.0110581,-0.03210184,-0.01228967,-0.0829637,0.02860161,-0.00223727,-0.0173773,0.03296661,-0.01524152,-0.04827386,-0.04021466,-0.06347235,-0.03014236,-0.03872186,-0.03241699,-0.01298359,-0.00200093,-0.02414501,0.06044258,-0.0466237,-0.01010943,-0.01462257,-0.01226135,-0.01024607,0.09253874,-0.0298725,0.02741307,-0.02116416,0.0182311,-0.03723273,-0.04097677,-0.04874079,0.03385602,0.02588427,-0.01400795,0.00202996,0.02414092,0.02507086,-0.05274867,-0.19635248,-0.07819448,0.00582404,0.00359804,0.0333438,-0.07060923,0.06332809,-0.00008681,-0.05572368,0.0309634,0.10348316,0.0151415,-0.07054073,-0.06012859,0.02022607,0.03880199,0.00688434,-0.01725953,-0.00395341,-0.04016421,-0.0056014,0.04575973,0.05294483,-0.04072675,0.04720024,0.04768185,0.1550913,0.02253162,0.09756544,0.03831211,0.02749792,-0.04476452,-0.03713072,-0.03030527,0.03391553,0.01765252,0.06180981,-0.03896387,0.00156816,-0.02034647,-0.06176583,-0.00427659,0.00365979,-0.03198287,-0.01438579,0.08323349,-0.03676404,0.0325781,-0.04839161,0.03179709,-0.01149385,-0.00970115,0.05157843,0.07694476,0.00878238,-0.08012562,-0.02808978,-0.00471571,-0.0296628,0.03213126,-0.0190076,-0.10399305,-0.0149122,-0.09831364,0.05614381,-0.03185033,-0.00600862,-0.02384857,0.07610402,-0.00907845,-0.01633608,0.14615496,0.00325459,0.02739978,0.06477626,0.02129057,0.02998968,0.02116905,-0.00876091,-0.02522675,0.03858396,-0.00706595,-0.00535271,-0.01263103,0.03706168,-0.01229226,0.07285058,-0.07293328,0.03015165,-0.0079248,-0.03269541,0.00375993,0.01199394,0.0321672,0.05323048,-0.0135097,-0.24704324,0.00503006,0.03392635,0.05930827,-0.06664518,-0.05316503,0.08794501,-0.0438292,-0.04624006,0.00789463,0.06352071,0.03883445,0.02267601,0.00567434,-0.00716422,0.02371396,0.03528608,-0.00238561,0.0154432,-0.06212565,0.01557562,0.04838327,0.18864362,-0.07909334,0.05064415,0.05080726,-0.01920437,-0.02839276,0.06499356,-0.0668765,0.077646,0.0010731,0.06664979,0.00454356,-0.04069239,0.06039228,-0.03206436,0.04723108,0.02571098,0.00644907,-0.01306625,0.03602986,-0.07687445,-0.03800205,0.0878995,-0.01824469,0.05337371,-0.08695247,0.01260733,0.03922484,0.04662571,0.04343786,-0.000914,-0.02315058,0.02457021,0.03131199,-0.01362716,0.01730942,-0.07649501,0.03486985,0.01191329,-0.03698851,0.03899204,0.05047714,-0.05457788],"last_embed":{"hash":"1i2zq7r","tokens":123}}},"text":null,"length":0,"last_read":{"hash":"1i2zq7r","at":1756337149883},"key":"Computer Science/Machine Learning/Activation Functions.md##How do they work?#{1}","lines":[7,13],"size":413,"outlinks":[{"title":"Machine Learning","target":"Machine Learning","line":1},{"title":"sigmoid function","target":"sigmoid function","line":1},{"title":"ReLU Activation","target":"ReLU Activation","line":2},{"title":"Linear Activation","target":"Linear Activation","line":3},{"title":"Sigmoid Activation","target":"Sigmoid Activation","line":4},{"title":"Softmax Activation","target":"Softmax Activation","line":5}],"class_name":"SmartBlock","last_embed":{"hash":"1i2zq7r","at":1756337149883}},
