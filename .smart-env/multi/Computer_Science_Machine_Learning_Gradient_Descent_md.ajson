
"smart_sources:Computer Science/Machine Learning/Gradient Descent.md": {"path":"Computer Science/Machine Learning/Gradient Descent.md","last_embed":{"hash":null},"embeddings":{},"last_read":{"hash":"1wi6ngc","at":1756337133356},"class_name":"SmartSource","last_import":{"mtime":1756335618063,"size":1341,"at":1756337133365,"hash":"1wi6ngc"},"blocks":{"#":[1,1],"##How does gradient descent work for algorithms?":[2,4],"##How does gradient descent work for algorithms?#{1}":[3,4],"#What is the algorithm mathematically?":[5,9],"#What is the algorithm mathematically?#{1}":[6,9]},"outlinks":[{"title":"Derivative","target":"Derivative","line":1},{"title":"gradient descent ex.png","target":"gradient descent ex.png","line":1},{"title":"Weights and Biases","target":"Weights and Biases","line":1},{"title":"features vs examples","target":"features vs examples","line":3},{"title":"weight/biases","target":"Weights and Biases","line":3},{"title":"weights","target":"Weights and Biases","line":3}],"task_lines":[]},
"smart_sources:Computer Science/Machine Learning/Gradient Descent.md": {"path":"Computer Science/Machine Learning/Gradient Descent.md","embeddings":{"TaylorAI/bge-micro-v2":{"vec":[-0.05385185,-0.0053377,0.00844773,0.02281015,-0.01249269,0.03734882,-0.03402206,0.02913854,0.08632576,0.03735522,0.065208,-0.02939385,0.03790431,0.04213696,0.02577596,0.03056365,-0.02643221,0.02980153,-0.04284443,-0.04428603,0.05369007,-0.02371541,-0.01412239,-0.05916722,0.0420441,-0.02571581,-0.04700456,0.04736802,-0.03347035,-0.23059861,0.05155155,-0.0348384,0.05464392,-0.01354547,-0.00569214,0.03511519,-0.01036634,-0.00433169,-0.03113011,0.00691293,-0.0260972,0.03517795,-0.08557156,-0.03696635,0.01263039,-0.03426338,-0.03935691,-0.05770714,-0.10157892,0.04869661,0.0012523,0.00186326,0.04642216,-0.01145238,-0.01424574,0.01570308,0.05888366,0.08431051,0.05787449,0.02788142,0.02165605,0.05183347,-0.16506727,0.05560572,-0.00354607,-0.00614446,-0.00533945,-0.08314222,0.02489238,0.10227061,0.01088867,0.04136593,0.07278136,-0.01953251,0.00554882,0.00992261,0.03080061,0.00489205,0.02064725,-0.00231742,0.05556051,0.00412241,-0.06178598,-0.03549661,0.02246516,-0.06330287,0.05115759,0.00085098,0.06525993,0.00377515,0.02320395,-0.0528603,-0.04608653,0.00880021,-0.01773818,0.06425339,0.05137189,0.01444303,-0.10305479,0.11310129,-0.03781705,0.04268047,-0.00330385,0.00655736,-0.04133819,-0.01257503,-0.03530024,-0.0294338,0.00890203,-0.03445834,-0.06154241,-0.01041542,0.05973614,0.01076164,-0.07276501,0.00723335,-0.03352799,0.03332553,-0.01287409,-0.00452487,-0.03507592,-0.01317867,0.06593806,0.02875549,0.03819447,-0.03100599,-0.046833,0.08916752,0.01367203,0.02095914,0.09902743,-0.03576327,-0.05911845,-0.02811818,0.03571676,0.02762134,0.02280336,-0.01110542,0.01145538,-0.00607423,-0.08594372,0.02131451,0.0085381,-0.07615507,-0.10425583,0.16721451,-0.03771034,-0.00209587,-0.00182487,-0.09594903,-0.00193773,-0.01134466,-0.06034411,-0.01911998,-0.01047613,0.03509042,0.03838565,-0.02352581,-0.14558357,0.06227745,-0.08196317,0.0129258,-0.02142436,0.11517018,0.03473854,-0.01708293,-0.03889074,-0.04275454,0.00417042,0.00554716,0.09598185,0.05203277,-0.02496292,-0.02741072,0.01927463,-0.03331701,-0.10915854,-0.01429406,-0.02799798,-0.00517105,0.02774191,0.00064825,-0.05463841,-0.00275406,0.02749558,0.00489631,-0.0025287,-0.06506617,0.00511427,0.03477197,-0.07094241,-0.02831264,0.0213963,-0.05334302,-0.01665171,-0.04924664,-0.0187337,0.00896254,0.02208945,0.01514142,-0.02150916,0.0178495,0.06105382,0.00030118,-0.01352532,-0.0035764,0.05095543,-0.02403831,0.02068263,0.01472732,-0.0460883,-0.07095866,0.01598521,-0.04897595,-0.01435385,0.01270583,0.04995899,-0.00144778,-0.03457254,0.03118127,0.01985354,-0.01463498,-0.04582484,-0.14507969,-0.06764394,0.02696237,-0.01914545,-0.00295703,-0.06008823,0.07588682,-0.00674247,-0.00023773,0.0493315,0.08478726,-0.01239319,0.02435005,-0.02290724,0.03846871,0.01374045,0.04678674,0.01329399,0.01038791,-0.00412696,-0.03075827,0.01965442,0.07090356,-0.09794337,0.03422049,0.00753416,0.10643397,-0.05117229,0.09902587,0.02314813,-0.01638132,-0.04371029,0.03879276,0.00961088,0.04612298,-0.02833417,0.07084297,-0.04573779,-0.01132524,0.01576336,-0.00489729,0.04057237,0.04669112,-0.07642605,-0.1008248,-0.00553656,-0.02025819,0.01589859,-0.05484015,0.05466808,0.01594977,-0.00122004,0.03997751,-0.07291882,0.06065493,-0.06019229,-0.06329302,0.01272278,-0.02343247,0.0139877,0.03003426,-0.10606236,0.0000171,-0.03041226,0.09346352,-0.04065997,0.03798158,-0.0127202,0.01283473,-0.00102398,-0.01076541,0.11506924,0.07209662,0.01718623,0.00084431,0.00303126,0.04368169,0.04925202,-0.05007759,-0.00109656,0.01225212,-0.0234738,0.01680884,0.08060281,-0.01930306,-0.01514488,0.07837331,-0.06304012,0.01528761,0.02051331,-0.10138559,-0.00784283,-0.06192135,0.02072169,0.0177046,-0.00480201,-0.20759709,-0.00192077,0.01296829,-0.00956648,0.0190163,0.00011586,0.09852266,-0.00341423,-0.04141387,0.00088315,-0.05583968,0.06745883,0.01853195,-0.01125799,0.06481205,0.00444514,0.05730153,0.02418338,0.04805492,-0.0644815,0.00724152,0.08274672,0.17494902,-0.08629298,0.0278205,0.00201534,-0.04544076,0.00302167,0.05950313,-0.02552269,-0.03756925,0.00609635,0.13664407,-0.06321565,0.01426678,0.11391662,-0.02629545,-0.02095659,0.05515558,0.00881565,0.04455415,0.02655099,0.00922083,0.01734644,0.05471814,0.08594814,0.03426538,-0.05417646,-0.07808844,0.00092776,-0.00910471,0.06327256,0.03858579,-0.04428042,0.08557116,0.03055315,-0.08141197,-0.03033362,-0.041798,-0.01947298,0.05563072,-0.0578479,-0.04694679,-0.00864943,-0.03008675],"last_embed":{"hash":"1wi6ngc","tokens":324}}},"last_read":{"hash":"1wi6ngc","at":1756337150031},"class_name":"SmartSource","last_import":{"mtime":1756335618063,"size":1341,"at":1756337133365,"hash":"1wi6ngc"},"blocks":{"#":[1,1],"##How does gradient descent work for algorithms?":[2,4],"##How does gradient descent work for algorithms?#{1}":[3,4],"#What is the algorithm mathematically?":[5,9],"#What is the algorithm mathematically?#{1}":[6,9]},"outlinks":[{"title":"Derivative","target":"Derivative","line":1},{"title":"gradient descent ex.png","target":"gradient descent ex.png","line":1},{"title":"Weights and Biases","target":"Weights and Biases","line":1},{"title":"features vs examples","target":"features vs examples","line":3},{"title":"weight/biases","target":"Weights and Biases","line":3},{"title":"weights","target":"Weights and Biases","line":3}],"task_lines":[],"last_embed":{"hash":"1wi6ngc","at":1756337150010}},"smart_blocks:Computer Science/Machine Learning/Gradient Descent.md#": {"path":null,"embeddings":{"TaylorAI/bge-micro-v2":{"vec":[-0.06025596,0.03691815,0.00873011,0.0475127,0.01049991,0.0305706,-0.01904449,0.02381457,0.06838797,0.0389878,0.07396527,-0.04979609,0.03199449,0.03522087,0.02268229,0.03714457,-0.02138146,0.05451716,-0.02483334,-0.03745281,0.07132621,0.0120462,-0.04964392,-0.08717369,0.04933648,-0.03637676,-0.04958829,0.01513215,-0.03756789,-0.17339262,0.05549918,-0.01877754,0.0685114,-0.01123401,0.01568397,0.03659901,-0.00910171,0.01076147,-0.06054713,0.00898219,-0.03887781,0.01077476,-0.09079504,-0.01354803,0.03910685,-0.02833772,-0.02480099,-0.06061267,-0.11001064,0.00715737,0.02142979,-0.00883803,0.05551464,-0.00176087,-0.00857313,-0.00338337,0.04421747,0.06482897,0.0525999,0.01307645,0.02529079,0.0496144,-0.15592019,0.03250753,-0.02017791,0.01273665,-0.00077655,-0.0795201,0.03003548,0.0984634,0.01410656,0.01628633,0.05033841,-0.00146857,-0.01261364,0.03612174,0.05692459,-0.02121511,0.00501049,-0.01240021,0.05845507,-0.01204772,-0.060551,-0.05589053,0.01751075,-0.05360389,0.01248679,0.02507567,0.08211258,0.00756963,0.00810153,-0.04948256,-0.04247841,-0.00041266,-0.00446756,0.03525062,0.03243181,-0.00071629,-0.07186396,0.14044686,-0.04225796,0.04996584,-0.01811139,-0.01332714,-0.03258673,-0.03664001,-0.01313039,-0.01698461,0.0158962,-0.05523419,-0.07050084,-0.00766951,0.0830381,0.03332625,-0.06061959,-0.01205584,-0.03808849,0.07946312,-0.0119284,-0.00838839,-0.04221186,-0.02529993,0.06628216,0.0273356,0.04057179,-0.0570842,-0.05021637,0.09660916,0.00463451,0.0170097,0.08977802,-0.01572499,-0.04552826,-0.04015137,0.05288092,0.03573318,0.01582364,-0.02475001,0.00434797,-0.01862265,-0.09271694,0.04942553,0.02849121,-0.07443687,-0.11377099,0.13934216,-0.04862508,-0.00247282,-0.03127145,-0.07649952,0.00464879,-0.01612807,-0.04173121,-0.04718217,-0.00742015,0.03716204,0.05362096,-0.02389769,-0.12563814,0.05742586,-0.0589924,-0.01952969,-0.03189963,0.14159013,0.04228231,-0.03419956,-0.02505757,-0.04021944,0.01157204,0.0183017,0.1161475,0.05647672,-0.03136558,0.00158039,0.02038651,-0.03356735,-0.08462524,-0.01471924,-0.04018528,-0.03249833,0.02593846,-0.01478038,-0.04206063,0.02097635,0.06104709,0.01645435,0.01453675,-0.04967227,-0.00801547,0.01162674,-0.07554358,-0.04387244,0.00315887,-0.05980848,0.01129175,-0.0427467,0.00196757,0.01837936,0.01491416,0.00157315,-0.05913548,0.01469106,0.03800543,0.02981509,-0.0347093,0.00774594,0.04395952,-0.04550697,0.00827733,0.01292027,-0.04511327,-0.09224416,0.03875359,-0.04340021,-0.01496623,0.02965664,0.03693274,-0.01829022,-0.05181872,0.04831639,0.01303569,-0.01422031,-0.04322744,-0.13968641,-0.07214155,0.02373596,0.00190106,-0.00734029,-0.05581761,0.04865886,-0.01866702,0.02293307,0.03592553,0.09481525,-0.00020669,0.00726664,-0.02377503,0.03835797,0.00676471,0.03006705,0.02889544,-0.00555314,0.01543264,-0.00212694,0.01345416,0.07844736,-0.08791846,-0.00243562,0.01711414,0.12395311,-0.0178679,0.13110988,0.02573404,-0.03721172,-0.00609444,-0.00048605,-0.01585621,0.0598692,-0.04389967,0.06079087,-0.04914644,-0.0178626,0.00729887,-0.03035944,0.05346309,0.04983848,-0.08064707,-0.0823416,-0.00254458,-0.02319388,0.01613246,-0.0199258,0.05530723,0.01345528,-0.00765146,0.02585247,-0.06834932,0.0476613,-0.04926576,-0.08674484,0.01433279,-0.02689798,0.01260431,0.02737635,-0.12284221,-0.00653532,-0.03470977,0.06441692,-0.03141321,0.02384158,-0.01992216,-0.01413204,-0.00546466,0.00772352,0.14035229,0.07980111,0.01411755,-0.00739368,0.00606111,0.04134041,0.02971275,-0.0584387,-0.00403106,0.02028299,-0.02974609,0.04397458,0.08027094,0.00383289,-0.01331502,0.07652272,-0.07628871,0.04124735,0.01217333,-0.09464165,-0.00775802,-0.0817979,0.02056312,0.01805823,-0.00770697,-0.20501131,0.00629182,0.01217551,0.00783382,0.0301385,0.00871215,0.09673078,0.00046122,-0.03364849,0.02870806,-0.06857955,0.04302416,0.01574941,-0.01206635,0.0529013,0.00818119,0.07860682,-0.00245561,0.04586018,-0.05753133,0.00473536,0.06829433,0.16320959,-0.06677841,0.0385901,-0.01063744,-0.02816841,-0.03869385,0.0157799,-0.03969665,-0.03265575,-0.03106011,0.14728114,-0.06346159,0.02377268,0.14048748,-0.00274693,-0.00470876,0.04940392,-0.00183662,0.01280345,0.0096403,0.0077037,-0.00181657,0.05356064,0.0924613,0.03846515,-0.04957577,-0.04797159,0.00626353,-0.00944665,0.06727705,0.00454752,-0.0107289,0.09410348,0.04180167,-0.06640956,-0.04763229,-0.03403022,-0.03205878,0.04980231,-0.0818819,-0.00241667,-0.00280352,-0.04211345],"last_embed":{"hash":"1dafztm","tokens":68}}},"text":null,"length":0,"last_read":{"hash":"1dafztm","at":1756337150018},"key":"Computer Science/Machine Learning/Gradient Descent.md#","lines":[1,1],"size":251,"outlinks":[{"title":"Derivative","target":"Derivative","line":1},{"title":"gradient descent ex.png","target":"gradient descent ex.png","line":1},{"title":"Weights and Biases","target":"Weights and Biases","line":1}],"class_name":"SmartBlock","last_embed":{"hash":"1dafztm","at":1756337150018}},
"smart_blocks:Computer Science/Machine Learning/Gradient Descent.md##How does gradient descent work for algorithms?#{1}": {"path":null,"embeddings":{"TaylorAI/bge-micro-v2":{"vec":[-0.06254812,-0.01397463,-0.00752319,0.01132362,-0.01899848,0.03180419,-0.02348021,0.01665466,0.07986164,0.04376294,0.05716053,-0.0305778,0.03730925,0.04177398,0.0235543,0.03239209,-0.03133766,0.01731008,-0.04988218,-0.08591803,0.04055662,-0.01863487,-0.02046996,-0.02437669,0.02260983,-0.01965051,-0.06184425,0.04268392,-0.03255085,-0.25660506,0.04013333,-0.05277287,0.06500656,0.00744826,-0.02402885,0.03689811,0.0040937,-0.01148357,-0.0373766,0.00639039,-0.00219195,0.04510652,-0.06690045,-0.04978958,0.01166704,-0.0096707,-0.03828654,-0.05503197,-0.08898897,0.05215985,0.03468499,0.00487795,0.03855311,0.01438051,-0.04442277,0.03817919,0.07217532,0.08160231,0.04693623,0.02124068,0.04705761,0.04946252,-0.16001046,0.06614964,0.01119663,-0.01366513,-0.01465104,-0.10509437,0.01117778,0.10110011,0.01616364,0.04167562,0.06719786,-0.01423054,0.02085668,-0.00261761,0.02656639,0.027073,0.00768112,-0.00724546,0.0380103,-0.01394191,-0.05145749,-0.03011599,0.02903039,-0.04100394,0.03265038,-0.00229467,0.06543705,0.00060532,0.02004479,-0.0482002,-0.04127424,0.01778566,-0.01477607,0.08072145,0.0602621,-0.01035652,-0.09821939,0.13537678,-0.05215509,0.03398713,-0.00582866,0.04150294,-0.02980041,0.02393661,-0.04960355,-0.03821607,0.00035894,-0.0025347,-0.04305295,-0.01994115,0.05198527,0.01429579,-0.05526407,0.00799881,-0.03756029,0.01130647,-0.01058015,-0.01344732,-0.02847573,-0.00444084,0.06809451,0.02560601,0.05390479,-0.01409539,-0.0340193,0.08146556,0.01010873,0.0203594,0.10095777,-0.05162202,-0.06387078,-0.01750732,0.02214675,0.02462745,0.06298477,-0.00920993,0.02376726,-0.01486603,-0.05605042,0.02983947,0.01511597,-0.06931475,-0.08890313,0.17821452,-0.02705489,0.01329284,0.02189059,-0.07510137,-0.02990469,-0.01431064,-0.08036578,-0.01245656,-0.02441087,0.03707333,0.00856508,-0.04724003,-0.14652368,0.04332926,-0.08384341,0.02606262,-0.03466339,0.08551212,0.03102018,-0.00537792,-0.03157211,-0.01344895,-0.00187252,-0.01661517,0.08673551,0.03580831,-0.02032914,-0.03891014,0.02057857,-0.03637646,-0.11032143,-0.01989128,-0.00293908,0.00811858,0.01798053,0.01159195,-0.05591739,0.00328942,0.01186541,-0.00119535,-0.0254137,-0.07427655,0.02475378,0.03546685,-0.08613279,-0.02772759,0.04127508,-0.06709264,-0.02714918,-0.04197732,-0.05290354,0.00611374,0.01152205,0.01667238,-0.02288076,0.01370843,0.07684301,-0.00649658,-0.00311625,-0.01205269,0.03171935,-0.0292551,0.03139079,0.0203007,-0.04511102,-0.05236273,-0.0205585,-0.05107712,-0.0251355,-0.00650117,0.03863409,-0.00258934,-0.00873779,0.0241175,0.01977797,-0.03448074,-0.05006572,-0.15848029,-0.07807024,0.02001505,-0.04534704,0.0161382,-0.04976346,0.07621579,0.01940113,-0.03599146,0.05828427,0.08168857,-0.01978213,0.02776398,-0.02465011,0.02759993,0.01703445,0.02415351,0.00770758,0.00421686,-0.00653666,-0.01133942,0.01960743,0.07900815,-0.09810443,0.06855164,0.00352982,0.10807077,-0.0493463,0.09912517,0.04649705,-0.0071141,-0.05079507,0.02658786,-0.01747755,0.08003189,-0.02122162,0.05086043,-0.04413599,-0.00384295,0.02722448,-0.02191426,0.04692855,0.05305756,-0.06569321,-0.09051169,0.00367011,-0.00926976,-0.00361458,-0.03568074,0.05844662,-0.00882975,0.0135167,0.03754937,-0.03784952,0.05573488,-0.05289659,-0.05774177,0.00919125,-0.02449244,0.02272902,0.02339122,-0.09847204,-0.01134371,-0.01019864,0.10672105,-0.03150624,0.04302396,-0.01757283,0.0424656,0.01510966,-0.01615819,0.11479262,0.03755303,0.02086264,-0.01354436,0.00348915,0.00735363,0.04105559,-0.00737269,-0.00403675,0.00771834,-0.0329466,0.0138152,0.0936667,-0.00381625,-0.0218485,0.05891199,-0.03827839,0.01166503,0.00240685,-0.08554642,-0.01118279,-0.05557111,0.01857486,0.02150495,0.01309696,-0.20847774,0.00129268,0.01412373,-0.00808298,0.00207812,0.00452,0.09947583,0.01212301,-0.04231478,0.00280354,-0.04114104,0.06415134,0.01872147,-0.02260516,0.04366429,0.01352755,0.06587285,0.01492665,0.04556409,-0.08057518,0.01187788,0.08421282,0.19712846,-0.06473207,0.01319755,0.01234857,-0.04046889,0.00412551,0.04518732,0.00805033,-0.02498847,0.00891488,0.12847203,-0.05397459,0.00216358,0.11567034,-0.03502988,-0.034455,0.06981732,0.00973768,0.02255031,0.03320307,0.00731177,0.02425336,0.05185544,0.05885105,0.02310146,-0.04948819,-0.1007881,-0.01290471,-0.02281538,0.05113273,0.05231194,-0.04831554,0.07555017,0.021064,-0.08488385,-0.01601887,-0.04618708,-0.00949725,0.04988703,-0.02987364,-0.06594723,-0.0057626,-0.04068528],"last_embed":{"hash":"h32j9e","tokens":146}}},"text":null,"length":0,"last_read":{"hash":"h32j9e","at":1756337150025},"key":"Computer Science/Machine Learning/Gradient Descent.md##How does gradient descent work for algorithms?#{1}","lines":[3,4],"size":589,"outlinks":[{"title":"features vs examples","target":"features vs examples","line":1},{"title":"weight/biases","target":"Weights and Biases","line":1},{"title":"weights","target":"Weights and Biases","line":1}],"class_name":"SmartBlock","last_embed":{"hash":"h32j9e","at":1756337150025}},
"smart_blocks:Computer Science/Machine Learning/Gradient Descent.md#What is the algorithm mathematically?#{1}": {"path":null,"embeddings":{"TaylorAI/bge-micro-v2":{"vec":[-0.05775974,-0.02692791,0.02135515,-0.01983451,-0.0214078,0.0526845,-0.02362755,0.06042795,0.08285798,0.02304203,0.04805074,-0.03048183,0.03878403,0.05818936,0.03409067,0.02679932,-0.02629192,0.04315218,-0.08760861,-0.01011091,0.07910713,-0.03716995,-0.0017893,-0.07130682,0.02081206,-0.00198825,0.00479009,0.03824912,-0.01708885,-0.21741514,0.01629381,-0.04648317,0.06676785,-0.0280738,0.01520573,0.02170134,-0.00835058,0.01006904,-0.03769372,0.0241244,-0.0128759,0.00690346,-0.0526561,-0.01762909,0.01091599,-0.07252028,-0.02059438,-0.03781254,-0.10313465,0.04145543,-0.02078371,0.00635484,0.0565956,-0.01672366,0.04629807,0.02156232,0.04133552,0.07289827,0.07201666,0.03781073,0.00625006,0.03961465,-0.17050689,0.05711492,0.00691218,0.01759016,0.01502354,-0.08989871,0.02091109,0.12510957,-0.00392857,0.04883512,0.06248694,-0.01540131,-0.00700226,-0.01109132,0.00805807,-0.01897951,0.05305463,0.02065973,0.04769011,0.01773297,-0.05418419,-0.03706753,-0.01697778,-0.06312202,0.04185503,0.00353516,0.02891427,0.00624185,0.00498861,-0.06926759,-0.06224979,0.01383577,-0.02724523,0.04057355,0.03130772,0.01833734,-0.09265761,0.10117871,-0.03423416,0.03509994,0.02639509,-0.02301211,-0.02865297,-0.05788298,-0.04187256,-0.03197475,0.00121536,-0.05354713,-0.08179675,0.00496985,0.04575137,-0.0117936,-0.05497926,-0.00843748,-0.00281506,0.0491702,-0.004841,-0.00853203,-0.0058645,-0.0181913,0.06129616,0.02293719,0.02929699,-0.02355801,-0.04869962,0.08735792,0.02869097,0.02080176,0.07708978,-0.06103681,-0.046312,-0.02129446,0.02654093,0.02440158,0.00487482,0.00569446,-0.00738127,0.00565008,-0.07732612,0.00644739,-0.01435502,-0.08946747,-0.10411914,0.12650457,-0.04590971,0.00606961,0.00430626,-0.07409108,-0.00753294,-0.01214999,-0.04653196,-0.01785169,-0.00524127,0.05461599,0.05210127,0.00937349,-0.11688229,0.0458746,-0.09845359,0.00418111,-0.00290006,0.14176872,0.05108945,0.00883206,-0.04363562,-0.02182642,0.01667107,0.01722324,0.08325092,0.08250244,-0.02516695,-0.01329956,0.03742485,-0.03367734,-0.1294644,-0.00547153,-0.03069639,-0.00611904,0.02937917,-0.0420728,-0.0402294,-0.0024466,0.03538317,0.00554118,0.01229916,-0.06132953,0.02233942,0.03205495,-0.03665739,-0.0051687,-0.01498584,-0.0621545,0.00017788,-0.04135171,-0.01374619,0.02178591,-0.00674215,0.00177997,0.00352518,0.0117973,0.0503354,0.01863098,-0.01583876,0.01008556,0.06720789,-0.00395704,0.02960278,0.00713376,-0.0675742,-0.08303887,0.00077354,-0.06078568,-0.00953967,0.02459119,0.05731731,-0.00043327,-0.03575681,0.0371908,-0.00071677,-0.01647317,-0.04883469,-0.16761188,-0.07303602,0.04676683,-0.01790787,0.02008481,-0.05316918,0.07017857,-0.01011735,0.02779359,0.03454854,0.06532713,0.00177317,0.0120864,-0.0208579,0.03342883,0.0356914,0.05771532,-0.01909815,0.01350143,0.00050147,-0.04394021,0.03802804,0.01616806,-0.09166231,-0.00057467,0.01002916,0.10359523,-0.02662881,0.10373867,-0.01727526,0.00220703,-0.03946776,0.03026812,0.0360647,0.00525261,-0.02342996,0.05069137,-0.06586034,-0.00362081,0.01171173,-0.02218243,0.03082002,0.04290151,-0.06619782,-0.07734558,0.00263852,-0.04531087,0.00450886,-0.0702126,0.04280505,0.01640082,-0.01355732,0.03568345,-0.04113457,0.05870355,-0.05566327,-0.06322547,-0.016456,-0.01765794,0.01586019,0.02482411,-0.08665643,0.01579156,-0.05444516,0.06556568,-0.03917471,0.00502778,0.00013687,0.01528336,-0.01662561,-0.02787978,0.07957666,0.09935509,0.00950442,0.02083959,-0.00069101,0.06849083,0.06239244,-0.04654026,-0.0085565,0.0164081,-0.00015959,0.02716176,0.08906646,-0.01765382,-0.0036871,0.07868523,-0.04116926,-0.01217837,0.01625334,-0.1231271,-0.00236141,-0.06882022,0.02338643,0.01833389,-0.03190294,-0.22188175,0.02433507,0.01727717,0.03392922,0.00517523,-0.01277777,0.11974599,-0.02208763,-0.05566807,-0.00606436,-0.03639545,0.05836923,0.00297393,-0.02339621,0.06140479,-0.00253118,0.03041713,0.00467017,0.0636124,-0.06195921,0.01307158,0.09652297,0.21032611,-0.06092447,0.01500936,0.04242685,-0.03053878,0.02720382,0.05893589,-0.03277676,-0.02775278,0.00796259,0.14501062,-0.06876053,0.03439028,0.09081202,-0.01681929,0.03059689,0.03698909,-0.01201153,0.07347669,0.01298987,-0.01948004,-0.01456659,0.06930739,0.09473372,0.02971906,-0.04476007,-0.0692772,0.02179771,0.02951063,0.05730296,0.03097011,-0.04752041,0.0510169,0.01647308,-0.09093753,-0.04847477,-0.05085652,-0.04725231,0.02972131,-0.04571751,-0.00286994,-0.0087789,-0.0249883],"last_embed":{"hash":"4gpd35","tokens":129}}},"text":null,"length":0,"last_read":{"hash":"4gpd35","at":1756337150031},"key":"Computer Science/Machine Learning/Gradient Descent.md#What is the algorithm mathematically?#{1}","lines":[6,9],"size":407,"outlinks":[],"class_name":"SmartBlock","last_embed":{"hash":"4gpd35","at":1756337150031}},
